{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LLaMA Token Analyzer - Complete Example\n",
    "\n",
    "This notebook demonstrates the complete functionality of the LLaMA Token Analyzer framework.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:48:45.739151Z",
     "start_time": "2025-03-31T20:48:45.737542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:48:46.480754Z",
     "start_time": "2025-03-31T20:48:46.477613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from returns.result import Success, Failure\n",
    "from work.llama_token_analyzer.visualization.main import visualize\n",
    "from work.llama_token_analyzer import (\n",
    "    ModelManager,\n",
    "    TokenAnalyzer,\n",
    "    TokenAnalysisStorage\n",
    ")\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Components\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T20:48:58.144307Z",
     "start_time": "2025-03-31T20:48:49.377681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_config = {\n",
    "    \"llm_id\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"device\": \"auto\",\n",
    "    \"torch_dtype\": \"float16\"\n",
    "}\n",
    "\n",
    "model_result = ModelManager.initialize(model_config)\n",
    "\n",
    "# Initialize other components\n",
    "storage = TokenAnalysisStorage(base_path=\"work/notebooks/output\")\n",
    "\n",
    "match model_result:\n",
    "    case Success(manager):\n",
    "        analyzer = TokenAnalyzer(manager)\n",
    "        analyze = analyzer.create_analysis_pipeline(storage)\n",
    "    case Failure(error):\n",
    "        raise RuntimeError(f\"Failed to load model: {error}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_token_analyzer.core.model:Loading model meta-llama/Llama-3.2-3B-Instruct\n",
      "INFO:llama_token_analyzer.core.model:Device map: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "860c38a4743246d780d6f52821ec86a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single Prompt Analysis\n"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-31T20:49:20.917714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Write a story with a plottwist\"\n",
    "\n",
    "analysis_result = analyze(prompt)\n",
    "\n",
    "match analysis_result:\n",
    "    case Success(r):\n",
    "        visualize(r, storage=storage)\n",
    "    case Failure(error):\n",
    "        raise RuntimeError(f\"Analysis pipeline failed: {error}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating token association:  12%|█▏        | 81/689 [04:36<4:36:02, 27.24s/token]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batch Analysis\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze multiple prompts\n",
    "difficult_prompts = [\n",
    "    \"111,111,111 × 111,111,111 = 12,345,678,987,654,321\",\n",
    "    \"Write a tiny story where every word is longer than the previous one\",  # Forces increasing token lengths\n",
    "    \"Replace all vowels with 'z' in: 'The quick brown fox'\",\n",
    "    # Tests character-level manipulation, creates unusual consonant clusters\n",
    "    \"Write a sentence using only words that are palindromes\",  # Forces rare word choices like \"noon\", \"deed\", \"madam\"\n",
    "    \"Count down from 5 using only words starting with that number's first letter\",\n",
    "    # Forces constrained vocabulary with numbers: \"five\", \"four\", \"three\"...\n",
    "    \"Create a 6-word story using ascending ASCII characters\",  # Forces character code progression\n",
    "    \"Make a sentence where each word starts with 'th'\",  # Creates unusual token repetitions\n",
    "    \"Write words that rhyme with 'xyz'\",  # Tests handling of impossible constraints\n",
    "    \"Spell HELLO using words that start with each letter backwards\",  # Forces specific initials in reverse\n",
    "    \"Create a sentence where each word contains double letters\",\n",
    "    # Forces unusual word patterns: \"book\", \"teeth\", \"little\"\n",
    "    \"Write a question using only four-letter words\",  # Forces fixed token lengths\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Processing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompts = [\n",
    "    *difficult_prompts,\n",
    "]\n",
    "# Analyze prompts in batch\n",
    "analysis_result_batch = analyze(prompts)\n",
    "match analysis_result_batch:\n",
    "    case Success(all_results):\n",
    "        [visualize(single_result, storage=storage) for single_result in all_results]\n",
    "    case Failure(error):\n",
    "        raise RuntimeError(f\"Batch analysis failed: {error}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
