{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LLaMA Token Analyzer - Complete Example\n",
    "\n",
    "This notebook demonstrates the complete functionality of the LLaMA Token Analyzer framework.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from returns.result import Success, Failure\n",
    "from llama_token_analyzer.visualization.main import visualize\n",
    "from llama_token_analyzer import (\n",
    "    ModelManager,\n",
    "    TokenAnalyzer,\n",
    "    TokenAnalysisStorage\n",
    ")\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Components\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_config = {\n",
    "    \"llm_id\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"device\": \"auto\",\n",
    "    \"torch_dtype\": \"float16\"\n",
    "}\n",
    "# model_config = {\n",
    "#     \"llm_id\": \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\n",
    "#     \"device\": \"auto\",\n",
    "#     \"torch_dtype\": \"float16\"\n",
    "# }\n",
    "\n",
    "model_result = ModelManager.initialize(model_config)\n",
    "\n",
    "# Initialize other components\n",
    "storage = TokenAnalysisStorage(base_path=\"output\")\n",
    "\n",
    "match model_result:\n",
    "    case Success(manager):\n",
    "        analyzer = TokenAnalyzer(manager)\n",
    "        analyze = analyzer.create_analysis_pipeline(storage)\n",
    "    case Failure(error):\n",
    "        raise RuntimeError(f\"Failed to load model: {error}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single Prompt Analysis\n"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "prompt = \"Answer with ok.\"\n",
    "\n",
    "analysis_result = analyze(prompt)\n",
    "\n",
    "match analysis_result:\n",
    "    case Success(r):\n",
    "        visualize(r, storage=storage)\n",
    "    case Failure(error):\n",
    "        raise RuntimeError(f\"Analysis pipeline failed: {error}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batch Analysis\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze multiple prompts\n",
    "difficult_prompts = [\n",
    "    \"111,111,111 Ã— 111,111,111 = 12,345,678,987,654,321\",\n",
    "    \"Write a tiny story where every word is longer than the previous one\",  # Forces increasing token lengths\n",
    "    \"Replace all vowels with 'z' in: 'The quick brown fox'\",\n",
    "    # Tests character-level manipulation, creates unusual consonant clusters\n",
    "    \"Write a sentence using only words that are palindromes\",  # Forces rare word choices like \"noon\", \"deed\", \"madam\"\n",
    "    \"Count down from 5 using only words starting with that number's first letter\",\n",
    "    # Forces constrained vocabulary with numbers: \"five\", \"four\", \"three\"...\n",
    "    \"Create a 6-word story using ascending ASCII characters\",  # Forces character code progression\n",
    "    \"Make a sentence where each word starts with 'th'\",  # Creates unusual token repetitions\n",
    "    \"Write words that rhyme with 'xyz'\",  # Tests handling of impossible constraints\n",
    "    \"Spell HELLO using words that start with each letter backwards\",  # Forces specific initials in reverse\n",
    "    \"Create a sentence where each word contains double letters\",\n",
    "    # Forces unusual word patterns: \"book\", \"teeth\", \"little\"\n",
    "    \"Write a question using only four-letter words\",  # Forces fixed token lengths\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Processing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompts = [\n",
    "    *difficult_prompts,\n",
    "]\n",
    "# Analyze prompts in batch\n",
    "analysis_result_batch = analyze(prompts)\n",
    "match analysis_result_batch:\n",
    "    case Success(all_results):\n",
    "        [visualize(single_result, storage=storage) for single_result in all_results]\n",
    "    case Failure(error):\n",
    "        raise RuntimeError(f\"Batch analysis failed: {error}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
